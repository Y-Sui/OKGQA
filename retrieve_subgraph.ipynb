{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sparqlwrapper openai tqdm pandas networkx numpy pandas label-studio guidance\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# !label-studio start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0f2c3482f46a'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm, trange\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# set the maximum number of retries\n",
    "MAX_RETRIES = 10\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "uuid = str(uuid.uuid4()).split(\"-\")[-1]\n",
    "uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the queries from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>type</th>\n",
       "      <th>placeholders</th>\n",
       "      <th>naturalness</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>dbpedia_entities</th>\n",
       "      <th>dbpedia_entities_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please describe Marie Curie's contributions to...</td>\n",
       "      <td>descriptive</td>\n",
       "      <td>{'person': 'Marie Curie'}</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'person': 'http://dbpedia.org/resource/Marie_...</td>\n",
       "      <td>{'person': 'Marie_Curie'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain the relationship between the United Na...</td>\n",
       "      <td>explanatory</td>\n",
       "      <td>{'entity A': 'United Nations', 'entity B': 'in...</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'entity A': 'http://dbpedia.org/resource/Unit...</td>\n",
       "      <td>{'entity A': 'United_Nations', 'entity B': 'Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on current advancements in artificial in...</td>\n",
       "      <td>predictive</td>\n",
       "      <td>{'entity': 'artificial intelligence', 'event':...</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'entity': 'http://dbpedia.org/resource/Artifi...</td>\n",
       "      <td>{'entity': 'Artificial_intelligence', 'event':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compare and contrast the educational philosoph...</td>\n",
       "      <td>comparative</td>\n",
       "      <td>{'entity A': 'John Dewey', 'entity B': 'Paulo ...</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'entity A': 'http://dbpedia.org/resource/John...</td>\n",
       "      <td>{'entity A': 'John_Dewey', 'entity B': 'Paulo_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do you evaluate the impact of the Industri...</td>\n",
       "      <td>critical</td>\n",
       "      <td>{'event': 'Industrial Revolution', 'field': 'm...</td>\n",
       "      <td>high</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'event': 'http://dbpedia.org/resource/Industr...</td>\n",
       "      <td>{'event': 'Industrial_Revolution', 'field': 'E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Compare and contrast the educational philosoph...</td>\n",
       "      <td>comparative</td>\n",
       "      <td>{'entity A': 'John Dewey', 'entity B': 'Maria ...</td>\n",
       "      <td>high</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'entity A': 'http://dbpedia.org/resource/John...</td>\n",
       "      <td>{'entity A': 'John_Dewey', 'entity B': 'Maria_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>How do you evaluate the impact of Rachel Carso...</td>\n",
       "      <td>critical</td>\n",
       "      <td>{'person': 'Rachel Carson', 'event': 'her work...</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'person': 'http://dbpedia.org/resource/Rachel...</td>\n",
       "      <td>{'person': 'Rachel_Carson', 'event': 'Silent_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Based on the current advancements in technolog...</td>\n",
       "      <td>predictive</td>\n",
       "      <td>{'entity': 'artificial intelligence', 'time': ...</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'entity': 'http://dbpedia.org/resource/Artifi...</td>\n",
       "      <td>{'entity': 'Artificial_intelligence', 'time': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Compare and contrast the similarities and diff...</td>\n",
       "      <td>comparative</td>\n",
       "      <td>{'entity A': 'traditional education systems', ...</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'entity A': 'http://dbpedia.org/resource/Educ...</td>\n",
       "      <td>{'entity A': 'Education', 'entity B': 'Massive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>How do you evaluate the impact of Leonardo da ...</td>\n",
       "      <td>critical</td>\n",
       "      <td>{'person': 'Leonardo da Vinci', 'field': 'art ...</td>\n",
       "      <td>high</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'person': 'http://dbpedia.org/resource/Leonar...</td>\n",
       "      <td>{'person': 'Leonardo_da_Vinci', 'field': 'Art'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question         type  \\\n",
       "0    Please describe Marie Curie's contributions to...  descriptive   \n",
       "1    Explain the relationship between the United Na...  explanatory   \n",
       "2    Based on current advancements in artificial in...   predictive   \n",
       "3    Compare and contrast the educational philosoph...  comparative   \n",
       "4    How do you evaluate the impact of the Industri...     critical   \n",
       "..                                                 ...          ...   \n",
       "789  Compare and contrast the educational philosoph...  comparative   \n",
       "790  How do you evaluate the impact of Rachel Carso...     critical   \n",
       "791  Based on the current advancements in technolog...   predictive   \n",
       "792  Compare and contrast the similarities and diff...  comparative   \n",
       "793  How do you evaluate the impact of Leonardo da ...     critical   \n",
       "\n",
       "                                          placeholders naturalness difficulty  \\\n",
       "0                            {'person': 'Marie Curie'}        high     medium   \n",
       "1    {'entity A': 'United Nations', 'entity B': 'in...        high     medium   \n",
       "2    {'entity': 'artificial intelligence', 'event':...        high     medium   \n",
       "3    {'entity A': 'John Dewey', 'entity B': 'Paulo ...        high     medium   \n",
       "4    {'event': 'Industrial Revolution', 'field': 'm...        high       hard   \n",
       "..                                                 ...         ...        ...   \n",
       "789  {'entity A': 'John Dewey', 'entity B': 'Maria ...        high       hard   \n",
       "790  {'person': 'Rachel Carson', 'event': 'her work...        high     medium   \n",
       "791  {'entity': 'artificial intelligence', 'time': ...        high     medium   \n",
       "792  {'entity A': 'traditional education systems', ...        high     medium   \n",
       "793  {'person': 'Leonardo da Vinci', 'field': 'art ...        high       hard   \n",
       "\n",
       "                                      dbpedia_entities  \\\n",
       "0    {'person': 'http://dbpedia.org/resource/Marie_...   \n",
       "1    {'entity A': 'http://dbpedia.org/resource/Unit...   \n",
       "2    {'entity': 'http://dbpedia.org/resource/Artifi...   \n",
       "3    {'entity A': 'http://dbpedia.org/resource/John...   \n",
       "4    {'event': 'http://dbpedia.org/resource/Industr...   \n",
       "..                                                 ...   \n",
       "789  {'entity A': 'http://dbpedia.org/resource/John...   \n",
       "790  {'person': 'http://dbpedia.org/resource/Rachel...   \n",
       "791  {'entity': 'http://dbpedia.org/resource/Artifi...   \n",
       "792  {'entity A': 'http://dbpedia.org/resource/Educ...   \n",
       "793  {'person': 'http://dbpedia.org/resource/Leonar...   \n",
       "\n",
       "                                   dbpedia_entities_re  \n",
       "0                            {'person': 'Marie_Curie'}  \n",
       "1    {'entity A': 'United_Nations', 'entity B': 'Pe...  \n",
       "2    {'entity': 'Artificial_intelligence', 'event':...  \n",
       "3    {'entity A': 'John_Dewey', 'entity B': 'Paulo_...  \n",
       "4    {'event': 'Industrial_Revolution', 'field': 'E...  \n",
       "..                                                 ...  \n",
       "789  {'entity A': 'John_Dewey', 'entity B': 'Maria_...  \n",
       "790  {'person': 'Rachel_Carson', 'event': 'Silent_S...  \n",
       "791  {'entity': 'Artificial_intelligence', 'time': ...  \n",
       "792  {'entity A': 'Education', 'entity B': 'Massive...  \n",
       "793    {'person': 'Leonardo_da_Vinci', 'field': 'Art'}  \n",
       "\n",
       "[794 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"filtered_questions_v3.csv\", index_col=0)\n",
    "df[\"dbpedia_entities\"] = df[\"dbpedia_entities\"].apply(lambda x: eval(x))\n",
    "df[\"placeholders\"] = df[\"placeholders\"].apply(lambda x: eval(x))\n",
    "df[\"dbpedia_entities_re\"] = df[\"dbpedia_entities\"].apply(\n",
    "    lambda x: {k: v.split(\"/\")[-1].split(\"#\")[-1] for k, v in x.items()}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPARQL Template for single entity, two entities and three entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARQL query for single entity\n",
    "single_entity_query = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "SELECT DISTINCT ?entity ?p ?firstHopEntity ?p2 ?secondHopEntity\n",
    "WHERE {{\n",
    "  {{\n",
    "    dbr:{entity} ?p ?firstHopEntity.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity} AS ?entity)\n",
    "  }} UNION {{\n",
    "    dbr:{entity} ?p ?firstHopEntity.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity}.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity}.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity} AS ?entity)\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# SPARQL query for two entities\n",
    "two_entity_query = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "SELECT DISTINCT ?entity ?p ?firstHopEntity ?p2 ?secondHopEntity\n",
    "WHERE {{\n",
    "    {{\n",
    "    dbr:{entity1} ?p ?firstHopEntity.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "    }} UNION {{\n",
    "    dbr:{entity1} ?p ?firstHopEntity.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "    }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity1}.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "    }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity1}.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "    }} UNION {{\n",
    "    dbr:{entity2} ?p ?firstHopEntity.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "    }} UNION {{\n",
    "    dbr:{entity2} ?p ?firstHopEntity.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "    }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity2}.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "    }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity2}.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "    }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# SPARQL query for three entities\n",
    "\n",
    "three_entity_query = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "SELECT DISTINCT ?entity ?p ?firstHopEntity ?p2 ?secondHopEntity\n",
    "WHERE {{\n",
    "  {{\n",
    "    dbr:{entity1} ?p ?firstHopEntity.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "  }} UNION {{\n",
    "    dbr:{entity1} ?p ?firstHopEntity.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity1}.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity1}.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity1} AS ?entity)\n",
    "  }} UNION {{\n",
    "    dbr:{entity2} ?p ?firstHopEntity.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "  }} UNION {{\n",
    "    dbr:{entity2} ?p ?firstHopEntity.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity2}.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity2}.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity2} AS ?entity)\n",
    "  }} UNION {{\n",
    "    dbr:{entity3} ?p ?firstHopEntity.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity3} AS ?entity)\n",
    "  }} UNION {{\n",
    "    dbr:{entity3} ?p ?firstHopEntity.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity3} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity3}.\n",
    "    ?firstHopEntity ?p2 ?secondHopEntity.\n",
    "    BIND(dbr:{entity3} AS ?entity)\n",
    "  }} UNION {{\n",
    "    ?firstHopEntity ?p dbr:{entity3}.\n",
    "    ?secondHopEntity ?p2 ?firstHopEntity.\n",
    "    BIND(dbr:{entity3} AS ?entity)\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_sparql(entities):\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "    if len(entities) == 1:\n",
    "        query = single_entity_query\n",
    "        query = query.format(entity=entities[0])\n",
    "    elif len(entities) == 2:\n",
    "        query = two_entity_query\n",
    "        query = query.format(entity1=entities[0], entity2=entities[1])\n",
    "    elif len(entities) == 3:\n",
    "        query = three_entity_query\n",
    "        query = query.format(\n",
    "            entity1=entities[0], entity2=entities[1], entity3=entities[2]\n",
    "        )\n",
    "\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_case = run_sparql(single_entity_query, [\"Albert_Einstein\"])\n",
    "# test_case_2 = run_sparql(two_entity_query, [\"Albert_Einstein\", \"Germany\"])\n",
    "# test_case_3 = run_sparql(three_entity_query, [\"Albert_Einstein\", \"Germany\", \"Berlin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save all the nodes/edges to NetworkX and then calculate the statistics of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value(obj):\n",
    "    if obj[\"type\"] == \"uri\":\n",
    "        return obj[\"value\"].split(\"/\")[-1].split(\"#\")[-1]\n",
    "    else:\n",
    "        return obj[\"value\"]\n",
    "\n",
    "\n",
    "def build_up_graph(rdfs):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        rdfs (dict): results from SPARQL query\n",
    "\n",
    "    Returns:\n",
    "        _type_: networkx graph\n",
    "    \"\"\"\n",
    "    # hold directed edges. self loops are allowed but multiple(parell) edges are not.\n",
    "    G = nx.DiGraph()\n",
    "    central_node = set()\n",
    "\n",
    "    for result in rdfs[\"results\"][\"bindings\"]:\n",
    "        node = extract_value(result[\"entity\"])\n",
    "        central_node.add(node)\n",
    "\n",
    "        first_hop_nei = extract_value(result[\"firstHopEntity\"])\n",
    "        second_hop_nei = extract_value(result[\"secondHopEntity\"])\n",
    "        r1 = extract_value(result[\"p\"])\n",
    "        r2 = extract_value(result[\"p2\"])\n",
    "\n",
    "        if node == first_hop_nei:\n",
    "            # dbr:entity --> first_hop_nei --> second_hop_nei\n",
    "            G.add_edge(node, first_hop_nei, relation=r1)\n",
    "            G.add_edge(node, second_hop_nei, relation=r2)\n",
    "        elif node == second_hop_nei:\n",
    "            # dbr:entity -> first_hop_nei <- second_hop_nei\n",
    "            G.add_edge(node, first_hop_nei, label=r1)\n",
    "            G.add_edge(second_hop_nei, first_hop_nei, label=r2)\n",
    "        elif first_hop_nei == second_hop_nei:\n",
    "            # first_hop_nei -> dbr:entity -> second_hop_nei\n",
    "            G.add_edge(first_hop_nei, node, label=r1)\n",
    "            G.add_edge(node, second_hop_nei, label=r2)\n",
    "        else:\n",
    "            # first_hop_nei -> dbr:entity <- second_hop_nei\n",
    "            G.add_edge(first_hop_nei, node, label=r1)\n",
    "            G.add_edge(second_hop_nei, first_hop_nei, label=r2)\n",
    "\n",
    "    return G, central_node\n",
    "\n",
    "\n",
    "class PPR_Utils:\n",
    "    # PPR to prune the graph\n",
    "    def __init__(self):\n",
    "        # define the parameters\n",
    "        self.alpha = 0.85\n",
    "        self.tol = 1e-6\n",
    "        self.max_iter = 100\n",
    "        self.threshold = 1e-5  # threshold for pruning, if the node's PPR is less than the threshold, it will be pruned\n",
    "\n",
    "    def calculate_ppr(self, G, central_node):\n",
    "        # calcultae Personalized PageRank\n",
    "        personalization = {node: 0 for node in G.nodes()}\n",
    "        # set the central node weight to 1\n",
    "        for node in list(central_node):\n",
    "            personalization[node] = 1\n",
    "\n",
    "        ppr = nx.pagerank(\n",
    "            G,\n",
    "            personalization=personalization,\n",
    "            alpha=self.alpha,\n",
    "            tol=self.tol,\n",
    "            max_iter=self.max_iter,\n",
    "        )\n",
    "        return ppr\n",
    "\n",
    "    def prune_graph(self, G, central_node):\n",
    "        pruned_G = nx.DiGraph()\n",
    "        ppr = self.calculate_ppr(G, central_node)\n",
    "\n",
    "        for node, score in ppr.items():\n",
    "            if score >= self.threshold:\n",
    "                pruned_G.add_node(node)\n",
    "\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            if u in pruned_G and v in pruned_G:\n",
    "                pruned_G.add_edge(u, v, **data)\n",
    "\n",
    "        return pruned_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the statistics of the builded graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(G: nx.DiGraph):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "       G (nx.DiGraph): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # statistics\n",
    "    print(\"Graph Statistics:\")\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "    # Degree statistics\n",
    "    in_degrees = [d for n, d in G.in_degree()]\n",
    "    out_degrees = [d for n, d in G.out_degree()]\n",
    "    total_degrees = [d for n, d in G.degree()]\n",
    "\n",
    "    print(f\"Average in-degree: {sum(in_degrees) / len(in_degrees):.2f}\")\n",
    "    print(f\"Average out-degree: {sum(out_degrees) / len(out_degrees):.2f}\")\n",
    "    print(f\"Average total degree: {sum(total_degrees) / len(total_degrees):.2f}\")\n",
    "\n",
    "    # Most common relations\n",
    "    relations = [data['label'] for u, v, data in G.edges(data=True)]\n",
    "    common_relations = Counter(relations).most_common(5)\n",
    "    print(\"\\nTop 5 most common relations:\")\n",
    "    for relation, count in common_relations:\n",
    "        print(f\"{relation}: {count}\")\n",
    "\n",
    "    # Number of connected components (for undirected version of the graph)\n",
    "    undirected_G = G.to_undirected()\n",
    "    num_components = nx.number_connected_components(undirected_G)\n",
    "    print(f\"\\nNumber of connected components: {num_components}\")\n",
    "\n",
    "    # Largest connected component\n",
    "    largest_cc = max(nx.connected_components(undirected_G), key=len)\n",
    "    print(f\"Size of the largest connected component: {len(largest_cc)}\")\n",
    "\n",
    "    # # Check if the graph is a DAG (Directed Acyclic Graph)\n",
    "    # is_dag = nx.is_directed_acyclic_graph(G)\n",
    "    # print(f\"\\nIs the graph a DAG? {is_dag}\")\n",
    "    # print(f\"Is the graph strongly connected? {nx.is_strongly_connected(G)}\")\n",
    "    # print(f\"Is the graph weakly connected? {nx.is_weakly_connected(G)}\")\n",
    "\n",
    "    # # Calculate the diameter of the largest connected component\n",
    "    # largest_cc_subgraph = undirected_G.subgraph(largest_cc)\n",
    "    # diameter = nx.diameter(largest_cc_subgraph)\n",
    "    # print(f\"Diameter of the largest connected component: {diameter}\")\n",
    "\n",
    "    # # Calculate the centrality of the top 5 nodes\n",
    "    # print(\"\\nCentrality Measures (for top 5 nodes):\")\n",
    "    # in_degree_centrality = nx.in_degree_centrality(G)\n",
    "    # print(\"Top 5 nodes by In-Degree Centrality:\")\n",
    "    # for node, centrality in sorted(\n",
    "    #     in_degree_centrality.items(), key=lambda x: x[1], reverse=True\n",
    "    # )[:5]:\n",
    "    #     print(f\"{node}: {centrality:.4f}\")\n",
    "\n",
    "    # out_degree_centrality = nx.out_degree_centrality(G)\n",
    "    # print(\"\\nTop 5 nodes by Out-Degree Centrality:\")\n",
    "    # for node, centrality in sorted(\n",
    "    #     out_degree_centrality.items(), key=lambda x: x[1], reverse=True\n",
    "    # )[:5]:\n",
    "    #     print(f\"{node}: {centrality:.4f}\")\n",
    "\n",
    "    # # Betweenness Centrality (can be slow for large graphs)\n",
    "    # betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    # print(\"\\nTop 5 nodes by Betweenness Centrality:\")\n",
    "    # for node, centrality in sorted(\n",
    "    #     betweenness_centrality.items(), key=lambda x: x[1], reverse=True\n",
    "    # )[:5]:\n",
    "    #     print(f\"{node}: {centrality:.4f}\")\n",
    "\n",
    "    # Clustering Coefficient\n",
    "    clustering_coefficient = nx.average_clustering(G)\n",
    "    print(f\"\\nAverage Clustering Coefficient: {clustering_coefficient:.4f}\")\n",
    "\n",
    "    # Shortest Paths\n",
    "    print(\"\\nShortest Path Statistics:\")\n",
    "    shortest_paths = dict(nx.all_pairs_shortest_path_length(G))\n",
    "    path_lengths = [\n",
    "        length for paths in shortest_paths.values() for length in paths.values()\n",
    "    ]\n",
    "    print(f\"Average Shortest Path Length: {np.mean(path_lengths):.2f}\")\n",
    "    print(f\"Maximum Shortest Path Length (Diameter): {max(path_lengths)}\")\n",
    "\n",
    "    # Density\n",
    "    density = nx.density(G)\n",
    "    print(f\"\\nGraph Density: {density:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building subgraphs...:   4%|█▌                                  | 34/794 [10:25<13:06:28, 62.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 9: syntax error at 'company' before ')'\\n\\nSPARQL query:\\n#output-format:application/sparql-results+json\\n\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX dbr: <http://dbpedia.org/resource/>\\nSELECT DISTINCT ?entity ?p ?firstHopEntity ?p2 ?secondHopEntity\\nWHERE {\\n  {\\n    dbr:Amazon_(company) ?p ?firstHopEntity.\\n    ?firstHopEntity ?p2 ?secondHopEntity.\\n    BIND(dbr:Amazon_(company) AS ?entity)\\n  } UNION {\\n    dbr:Amazon_(company) ?p ?firstHopEntity.\\n    ?secondHopEntity ?p2 ?firstHopEntity.\\n    BIND(dbr:Amazon_(company) AS ?entity)\\n  } UNION {\\n    ?firstHopEntity ?p dbr:Amazon_(company).\\n    ?firstHopEntity ?p2 ?secondHopEntity.\\n    BIND(dbr:Amazon_(company) AS ?entity)\\n  } UNION {\\n    ?firstHopEntity ?p dbr:Amazon_(company).\\n    ?secondHopEntity ?p2 ?firstHopEntity.\\n    BIND(dbr:Amazon_(company) AS ?entity)\\n  }\\n}\\n\\n\" occurred for subgraph 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building subgraphs...:   5%|█▉                                   | 42/794 [12:02<2:45:06, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 9: syntax error at '.' before '?p'\\n\\nSPARQL query:\\n#output-format:application/sparql-results+json\\n\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX dbr: <http://dbpedia.org/resource/>\\nSELECT DISTINCT ?entity ?p ?firstHopEntity ?p2 ?secondHopEntity\\nWHERE {\\n  {\\n    dbr:Apple_Inc. ?p ?firstHopEntity.\\n    ?firstHopEntity ?p2 ?secondHopEntity.\\n    BIND(dbr:Apple_Inc. AS ?entity)\\n  } UNION {\\n    dbr:Apple_Inc. ?p ?firstHopEntity.\\n    ?secondHopEntity ?p2 ?firstHopEntity.\\n    BIND(dbr:Apple_Inc. AS ?entity)\\n  } UNION {\\n    ?firstHopEntity ?p dbr:Apple_Inc..\\n    ?firstHopEntity ?p2 ?secondHopEntity.\\n    BIND(dbr:Apple_Inc. AS ?entity)\\n  } UNION {\\n    ?firstHopEntity ?p dbr:Apple_Inc..\\n    ?secondHopEntity ?p2 ?firstHopEntity.\\n    BIND(dbr:Apple_Inc. AS ?entity)\\n  }\\n}\\n\\n\" occurred for subgraph 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building subgraphs...:   6%|██▍                                  | 51/794 [13:29<2:03:24,  9.97s/it]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"OKG\")\n",
    "    os.mkdir(\"OKG/subgraphs\")\n",
    "    os.mkdir(\"OKG/subgraphs/raw\")\n",
    "    os.mkdir(\"OKG/subgraphs/pruned_ppr\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "error_subgraph_indices = []\n",
    "ppr = PPR_Utils()\n",
    "\n",
    "entry_nodes = []\n",
    "for entities in df[\"dbpedia_entities_re\"]:\n",
    "    entry_nodes.append(list(entities.values()))\n",
    "\n",
    "with tqdm(\n",
    "    total=len(entry_nodes), desc=\"Building subgraphs...\", leave=True, ncols=100\n",
    ") as pbar:\n",
    "    for index, entry_node in enumerate(entry_nodes):\n",
    "        try:\n",
    "            rdfs = run_sparql(entry_node)\n",
    "            G, central_node = build_up_graph(rdfs)\n",
    "            ppr_G = ppr.prune_graph(G, central_node)\n",
    "\n",
    "            # pbar.write(\n",
    "            #     f\"Graph {index}: Nodes = {G.number_of_nodes()}, Edges = {G.number_of_edges()}\"\n",
    "            # )\n",
    "            # pbar.write(\n",
    "            #     f\"Pruned Graph {index}: Nodes = {ppr_G.number_of_nodes()}, Edges = {ppr_G.number_of_edges()}\"\n",
    "            # )\n",
    "\n",
    "            pickle.dump(G, open(f\"OKG/subgraphs/raw/{index}.pkl\", \"wb\"))\n",
    "            pickle.dump(ppr_G, open(f\"OKG/subgraphs/pruned_ppr/{index}.pkl\", \"wb\"))\n",
    "        except Exception as e:\n",
    "            pbar.write(f\"Error: {e} occurred for subgraph {index}\")\n",
    "            error_subgraph_indices.append(index)\n",
    "            continue\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
